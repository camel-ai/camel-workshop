{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872981be",
   "metadata": {},
   "source": [
    "# CAMEL Cookbook - Object Detection with ACI.dev MCP Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c98d9",
   "metadata": {},
   "source": [
    "**Description:** Learn how to build an object detection agent using CAMEL AI and ACI.dev's MCP protocol for seamless ML tasks. \n",
    "\n",
    "‚≠ê Star us on [GitHub](https://github.com/camel-ai/camel), join our [Discord](https://discord.gg/EXAMPLE), or follow us on [X](https://x.com/camelaiorg)\n",
    "\n",
    "This cookbook shows how to build a powerful object detection agent using CAMEL AI connected to ACI.dev's MCP tools. We'll create an agent that analyzes images, detects objects like cars or trees, and explains results in natural language‚Äîall without writing complex ML code.\n",
    "\n",
    "**Key Learnings:**\n",
    "- Why agents need tools to be truly useful.\n",
    "- How MCP enables dynamic, aware tool usage for tasks like object detection.\n",
    "- Setting up CAMEL with ACI.dev for real-time image analysis.\n",
    "- Building and running your own object detection agent.\n",
    "- Handling outputs with summaries, tables, and visualized results.\n",
    "\n",
    "This setup uses CAMEL's `MCPToolkit` to connect to ACI.dev's MCP servers, powering object detection via Replicate's ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad4834",
   "metadata": {},
   "source": [
    "### üì¶ Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install camel-ai aci-mcp aci-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e21e0",
   "metadata": {},
   "source": [
    "Set up keys (ACI_API_KEY, LINKED_ACCOUNT_OWNER_ID, GOOGLE_API_KEY, REPLICATE_API_TOKEN) in `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e484b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf512d1",
   "metadata": {},
   "source": [
    "### Define CAMEL agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df8125d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "agent_name = \"ObjectDetectionAgent\"\n",
    "system_prompt=\"\"\"\n",
    "You are a specialized Object Detection Agent. Your primary function is to use the `REPLICATE.run` tool for object detection and present the findings in a user-friendly format. \"\n",
    "\"The user will provide a text prompt containing an image URL and a query. You must extract the `image` URL and the `query` object(s). \"\n",
    "\"Immediately call the `REPLICATE.run` tool. The `input` must be a dictionary with two keys: `image` (the URL) and `query` (a string of the object(s)). \"\n",
    "\"Do not ask for clarification; make a reasonable inference if the query is ambiguous. \"\n",
    "\"After receiving the tool's output, format your response as follows: \"\n",
    "\"- **Natural Language Summary:** Start with a detailed friendly, insightful analysis of the detection results in plain English. \"\n",
    "\"- **Markdown Table:** Create a markdown table with columns: 'Object', 'Confidence Score', and 'Bounding Box Coordinates'. \"\n",
    "\"- **Result Image:** If the tool provides a URL for an image with bounding boxes, display it using markdown: `![Detected Objects](URL_HERE)`. \"\n",
    "\"Whenever I give you a link, trigger the tool call, extract its outputs and links, and present me in a proper markdown format with detailed analysis from the tool call in natural language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de159dc",
   "metadata": {},
   "source": [
    "### MCP servers configuration using ACI.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b360b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<camel.toolkits.mcp_toolkit.MCPToolkit at 0x79b6b05d2bd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camel.toolkits import MCPToolkit\n",
    "mcp_config = {\n",
    "    \"mcpServers\": {\n",
    "        \"aci_apps\": {\n",
    "            \"command\": \"aci-mcp\",\n",
    "            \"args\": [\n",
    "                \"apps-server\",\n",
    "                \"--apps=REPLICATE\",\n",
    "                \"--linked-account-owner-id\",\n",
    "                \"tahakom\"\n",
    "            ],\n",
    "            \"env\": {\"ACI_API_KEY\": os.getenv(\"ACI_API_KEY\")},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "mcp_toolkit = MCPToolkit(config_dict=mcp_config)\n",
    "# await mcp_toolkit.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f65a18",
   "metadata": {},
   "source": [
    "Define the CAMEL agent with GEMINI 2.5 Flash model with Replicate MCP tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "\n",
    "tools = mcp_toolkit.get_tools()\n",
    "\n",
    "# Initialize Gemini model\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4_1,\n",
    ")\n",
    "\n",
    "# Create system message\n",
    "sys_msg = BaseMessage.make_assistant_message(\n",
    "    role_name=agent_name,\n",
    "    content=system_prompt,\n",
    ")\n",
    "\n",
    "agent = ChatAgent(model=model, system_message=sys_msg, tools=tools, memory=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c9a64",
   "metadata": {},
   "source": [
    "After create the agent, let's do some examples using Replicate to identify the following images:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304b8ff",
   "metadata": {},
   "source": [
    "Now you can start the interactive chat loop to analyze any image URL you provide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51551c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Object Detection Chat! Enter 'quit' to exit.\n",
      "Please provide an image URL and what objects you'd like to detect.\n",
      "Example format: Analyze this image for cars and people: [IMAGE_URL]\n",
      "\n",
      "Analysis Results:\n",
      "Based on the object detection analysis of the vegetable stall image, several types of produce were successfully identified. The model detected multiple instances of onions, with varying confidence levels. A large cabbage was also identified with a good confidence score. A single carrot and a zucchini were detected, each with a reasonable confidence. Additionally, a significant cluster of tomatoes was identified. It appears that cucumber and beet were not detected in this image based on the provided query.\n",
      "\n",
      "| Object | Confidence Score | Bounding Box Coordinates |\n",
      "|---|---|---|\n",
      "| carrot | 0.465 | [294, 916, 1001, 1438] |\n",
      "| cabbage | 0.497 | [110, 1982, 1436, 3150] |\n",
      "| onion | 0.412 | [742, 3535, 1378, 4186] |\n",
      "| onion | 0.423 | [778, 4032, 1507, 4837] |\n",
      "| onion | 0.373 | [10, 3733, 785, 4501] |\n",
      "| tomato | 0.409 | [1214, 2242, 3445, 3768] |\n",
      "| zucchini | 0.445 | [727, 1767, 1538, 2331] |\n",
      "\n",
      "![Detected Objects](https://replicate.delivery/xezq/TbgikvlkvC4LF5WUFXt4Us4IB8Rbnpigt54Y3eLq5er9iqFVA/result.png)\n",
      "\n",
      "Thank you for using the Object Detection Chat!\n"
     ]
    }
   ],
   "source": [
    "# Sample prompts for reference:\n",
    "# 1. \"Analyze the vegetable stall and identify all produce, including tomato, onion, cabbage, cucumber, zucchini, carrot, and beet, in this image: https://images.pexels.com/photos/2255935/pexels-photo-2255935.jpeg\"\n",
    "# 2. \"Analyze the busy street scene and identify all vehicles, such as car, bus, and truck, as well as people, in this image: https://www.livemint.com/rf/Image-621x414/LiveMint/Period1/2012/10/01/Photos/Road621.jpg\"\n",
    "# 3. \"Analyze the warehouse scene and identify persons, cardboard boxes, and conveyor belts in this image: https://media.business-humanrights.org/media/images/16278498935_dac4d8f223_o.2e16d0ba.fill-1000x1000-c50.jpg\"\n",
    "\n",
    "print(\"Welcome to the Object Detection Chat! Enter 'quit' to exit.\")\n",
    "print(\"Please provide an image URL and what objects you'd like to detect.\")\n",
    "print(\"Example format: Analyze this image for cars and people: [IMAGE_URL]\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nEnter your prompt: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Thank you for using the Object Detection Chat!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            print(\"Please enter a valid prompt with an image URL.\")\n",
    "            continue\n",
    "            \n",
    "        response = await agent.astep(user_input)\n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(response.msg.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Please try again with a different image URL or prompt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41f02d",
   "metadata": {},
   "source": [
    "Finally, we disconnect the MCP toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7ddd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "await mcp_toolkit.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atreus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
